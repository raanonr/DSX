{"metadata":{"guid":"0795b0f9-ab11-4569-8cbc-553043eb8619","url":"/v2/streaming_pipelines/0795b0f9-ab11-4569-8cbc-553043eb8619","created_at":"2018-02-07T14:33:32Z","updated_at":"2018-02-07T16:40:59Z","revision":1518021659249},"entity":{"name":"News_Topic_Classification","description":"This is an example of using the Python Machine Learning operator to automatically categorize the content of newsgroup text using an LDA model.","project_guid":"b62c91c4-142d-4451-ab89-4f79bd9473cb","graph":{"doc_type":"pipeline","version":"1.0","json_schema":"http://www.ibm.com/ibm/wdp/flow-v1.0/pipeline-flow-v1-schema.json","id":"","app_data":{"ui_data":{"name":"News_Topic_Classification"}},"primary_pipeline":"primary-pipeline","pipelines":[{"id":"primary-pipeline","runtime":"streams","nodes":[{"id":"messagehub_wb88qdub8wj","type":"binding","op":"ibm.streams.sources.messagehub","outputs":[{"id":"target","schema_ref":"schema0","links":[{"node_id_ref":"code_ml_bc3dir17bvn","port_id_ref":"source"}]}],"parameters":{"schema_mapping":[{"name":"text","type":"string","length":0,"path":"/text"}]},"connection":{"ref":"4b3ffbed-b1da-4a86-bfea-2ee74efad44f","project_ref":"b62c91c4-142d-4451-ab89-4f79bd9473cb","properties":{"asset":{"id":"newsData","name":"newsData","type":"topic","path":"/newsData"}}},"app_data":{"ui_data":{"label":"MessageHub: News","x_pos":20,"y_pos":220}}},{"id":"code_ml_bc3dir17bvn","type":"execution_node","op":"ibm.streams.operations.code-ml","outputs":[{"id":"target","schema_ref":"schema1","links":[{"node_id_ref":"objectstorage_v2_g1xixrbxu3e","port_id_ref":"source"}]}],"parameters":{"file_objects":[{"file_reference_name":"model_package","auto_refresh":false,"connection":{"ref":"988d832f-0302-4ee6-ae90-2b4d1242b355","project_ref":"b62c91c4-142d-4451-ab89-4f79bd9473cb","properties":{"asset":{"path":"/pyml/news.lda_model.pkg.gz","asset_types":[],"assets":[],"fields":[],"extended_metadata":[],"first":{"href":"https://api.dataplatform.ibm.com/v2/connections/988d832f-0302-4ee6-ae90-2b4d1242b355/assets?project_id=b62c91c4-142d-4451-ab89-4f79bd9473cb&offset=0&limit=100&path=%2Fpyml%2Fnews.lda_model.pkg.gz"},"total_count":1,"logs":[{"severity":"error","message":"CDICO2063E: The content of the file is not in a supported format.","details":{}},{"severity":"error","message":"CDICO2063E: The content of the file is not in a supported format.","details":{}}]}}}}],"code":"#\n# YOU MUST EDIT THE SCHEMA and add all attributes that you are returning as output.\n#\n# Supported Python libraries are listed here:\n# https://datascience.ibm.com/docs/content/streaming-pipelines/python_libs.html?context=analytics\n\nfrom gensim import utils, models\nimport numpy\nimport nltk\nimport re\n\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nnltk.download(\"wordnet\")\n\n# init() function will be called once on pipeline initialization\n# @state a Python dictionary object for keeping state. The state object is passed to the process function\ndef init(state):\n    state['lemmatizer'] = nltk.stem.WordNetLemmatizer()\n    state['pos_tagger'] = nltk.pos_tag\n\n\n# process() function will be invoked on every event tuple\n# @event a Python dictionary object representing the input event tuple as defined by the input schema\n# @state a Python dictionary object for keeping state over subsequent function calls\n# return must be a Python dictionary object. It will be the output of this operator.\n#        Returning None results in not submitting an output tuple for this invocation.\n# You must declare all output attributes in the Edit Schema window.\ndef process(event, state):\n    output = None\n    bigram_phraser = state['phraser']\n    categories = state['newsgroup_category']\n\n    if state['model'] and event['text'] and len(event['text']) > 0:\n        output = {}\n        tokens = preprocess_text(event['text'], state['lemmatizer'], state['pos_tagger'])\n        tokens = bigram_phraser[tokens]\n        topics = get_topic_probability_list(state['model'], tokens)\n        output['category'] = categories.get( closest_newsgroup(state['newsgroup_mean_topics'], topics))\n\n    # Append the original text and the model_id\n    if output != None:\n        output['text' ] = event['text']\n        output['model_id'] = state['model_id']\n\n    return output\n\n\ndef load_model_package(state, path_model_package):\n    \"\"\"\n    Reverse the packaging done by the bundle_package() function in the notebook.\n    The objects from the gzip-ed package are loaded in the state dictionary.\n    \"\"\"\n    import pickle, gzip\n\n    pkg = {}\n    try:\n        with open( path_model_package, 'rb') as pkg_file:\n            pkg_gz = pkg_file.read()\n            pkg = pickle.loads(gzip.decompress(pkg_gz))\n    except Exception as err:\n        print(err)\n\n    state['model_id'] = pkg.get('timestamp')\n    state['model']    = pkg.get('model')\n    state['phraser']  = pkg.get('phraser')\n    state['newsgroup_category']     = pkg.get('newsgroup_category')\n    state['newsgroup_mean_topics']  = pkg.get('newsgroup_mean_topics')\n\n\ndef preprocess_text(text, lemmatizer, pos_tagger):\n    text = re.sub(r'(?i)[^@ ]*@[^@ ]*', ' ', text)\n    text = re.sub(r'(?i)((From|Reply-To|Organization|Lines|Nntp-Posting-Host|X-Newsreader): [^\\n]*\\n)|(Subject: (re: )*)', ' ', text)\n    text = re.sub(r'(?i)([.,?!:;()\\[\\]{}\\-<>=$\\\\]+)|(_){2,}', ' ', text)\n    tokens = [lemmatizer.lemmatize(lemmatizer.lemmatize(word, pos='n'), pos='v')\n                for word,wordtype in pos_tagger(\n                    [tok for tok in utils.tokenize(text, lowercase=True, deacc=True, errors=\"ignore\") if len(tok) > 2]) \n                if wordtype in ['NN','NNS','NNP','JJ']]\n    return tokens\n\n\ndef get_topic_probability_list(model, textTokens):\n    topicList = []\n    textBOW = model.id2word.doc2bow(textTokens)\n    topicTuples = model.get_document_topics(textBOW, minimum_probability=0)\n    topicList = list(list(zip(*topicTuples))[1])\n    return topicList\n\n\ndef closest_newsgroup(mean_topics, topics):\n    distances = {}\n    for ng in mean_topics.keys():\n        distances[ng] = numpy.linalg.norm(mean_topics[ng] - topics)\n    return min(distances, key=distances.get)","schema_mapping":[{"name":"category","type":"string","length":0,"source_elem_name":"","target_elem_name":""},{"name":"text","type":"string","length":0,"source_elem_name":"","target_elem_name":""},{"name":"model_id","type":"string","length":0,"source_elem_name":""}]},"app_data":{"ui_data":{"label":"ML LDA Classifier","x_pos":270,"y_pos":220}}},{"id":"objectstorage_v2_g1xixrbxu3e","type":"binding","op":"ibm.streams.targets.objectstorage_v2","parameters":{"write_policy":"time","rolling_time_seconds":"30"},"connection":{"ref":"988d832f-0302-4ee6-ae90-2b4d1242b355","project_ref":"b62c91c4-142d-4451-ab89-4f79bd9473cb","properties":{"asset":{"path":"/pyml-output/news_categories.%TIME.csv","asset_types":[],"assets":[],"fields":[],"extended_metadata":[],"first":{"href":"https://api.dataplatform.ibm.com/v2/connections/988d832f-0302-4ee6-ae90-2b4d1242b355/assets?project_id=b62c91c4-142d-4451-ab89-4f79bd9473cb&offset=0&limit=100&path=%2Fpyml-output%2Fnews_categories.%25TIME.csv"},"total_count":0,"logs":[]}}},"app_data":{"ui_data":{"label":"COS: Categories","x_pos":540,"y_pos":220}}}]}],"schemas":[{"id":"schema0","fields":[{"name":"text","type":"string"}]},{"id":"schema1","fields":[{"name":"category","type":"string"},{"name":"text","type":"string"},{"name":"model_id","type":"string"}]}]},"engines":{"streams":{"instance_id":"779ee6ed-4f31-40d2-b59a-7a277c32a2d6"}}}}