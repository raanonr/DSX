{"metadata":{"guid":"cab3b533-f411-4594-86d6-d2d8dd01b1dc","url":"/v2/streaming_pipelines/cab3b533-f411-4594-86d6-d2d8dd01b1dc","created_at":"2017-12-04T14:37:50Z","updated_at":"2017-12-10T14:29:54Z","revision":1512916194565},"entity":{"name":"LDA_Topic_Classification","description":"","project_guid":"50ac5cb5-7ca8-46c5-9429-4b348df1f962","graph":{"doc_type":"pipeline","version":"1.0","json_schema":"http://www.ibm.com/ibm/wdp/flow-v1.0/pipeline-flow-v1-schema.json","id":"","app_data":{"ui_data":{"name":"LDA_Topic_Classification"}},"primary_pipeline":"primary-pipeline","pipelines":[{"id":"primary-pipeline","runtime":"streams","nodes":[{"id":"messagehub_kqlwr3q484n","type":"binding","op":"ibm.streams.sources.messagehub","outputs":[{"id":"target","schema_ref":"schema0","links":[{"node_id_ref":"code_ml_5j86dd49anq","port_id_ref":"source"}]}],"parameters":{"schema_mapping":[{"name":"text","type":"string","length":255,"path":"/text"},{"name":"stars","type":"double","path":"/stars"}]},"connection":{"ref":"5cc71be6-6cd3-47e3-ae67-85fab0516ec5","project_ref":"50ac5cb5-7ca8-46c5-9429-4b348df1f962","properties":{"asset":{"id":"testTopic1","name":"testTopic1","type":"topic","path":"/testTopic1"}}},"app_data":{"ui_data":{"label":"Message Hub","x_pos":-260,"y_pos":20}}},{"id":"code_ml_5j86dd49anq","type":"execution_node","op":"ibm.streams.operations.code-ml","outputs":[{"id":"target","schema_ref":"schema1","links":[{"node_id_ref":"objectstorage_v2_t5u28o9l8ur","port_id_ref":"source"}]}],"parameters":{"file_objects":[{"file_reference_name":"model","auto_refresh":false,"connection":{"ref":"212176ed-cb0d-400e-a7d7-007e4fd8364a","project_ref":"50ac5cb5-7ca8-46c5-9429-4b348df1f962","properties":{"asset":{"id":"/pyml/LDA_test_2updated.model.pickle","name":"/pyml/LDA_test_2updated.model.pickle","path":"/pyml/LDA_test_2updated.model.pickle","type":"unknown"}}}}],"code":"#\n# YOU MUST EDIT THE SCHEMA and add all attributes that you are returning as output.\n#\n# Python libraries that are supported and selected (âœ“) at the \"In Installer\" list at\n# https://docs.continuum.io/anaconda/packages/pkg-docs\n\nimport sys\n\n\n# init() function will be called once on pipeline initialization\n# @state a Python dictionary object for keeping state. The state object is passed to the process function\ndef init(state):\n\n    state['model'] = None\n    state['model_id'] = 0\n    state['stoplist'] = setStopWordList()\n\n\n# process() function will be invoked on every event tuple\n# @event a Python dictionary object representing the input event tuple as defined by the input schema\n# @state a Python dictionary object for keeping state over subsequent function calls\n# return must be a Python dictionary object. It will be the output of this operator.\n#        Returning None results in not submitting an output tuple for this invocation.\n# You must declare all output attributes in the Edit Schema window.\ndef process(event, state):\n\n    # Get the {topic, terms} for the current text\n    output = get_topic( state['model'], state['stoplist'], event['text'])\n    \n    if output != None:\n        output['model_id'] = state['model_id']\n        output['text' ] = event['text']\n    \n    return output\n\n\ndef load_model(state, path_model):\n    import gzip\n    import pickle\n\n    unPickledModel = None\n    if path_model:\n        pickledModel = None\n        with open( path_model, 'rb') as m:\n            pickledModel = m.read()\n        # Check for magic signature of gzip\n        if pickledModel != None and pickledModel.startswith(b\"\\x1f\\x8b\\x08\"):\n            pickledModel = gzip.decompress( pickledModel)\n        unPickledModel = pickle.loads(pickledModel)\n        if unPickledModel != None:\n            state['model'] = unPickledModel\n            state['model_id'] = state['model_id'] + 1\n\n\n# Use the model to determine the top topic for this text.\n# Return tuple with the topic, it's terms (describing the topic) and the original text.\ndef get_topic( model, stoplist, text):\n    from gensim import models, corpora, utils\n\n    topicTerms = {}\n\n    if model != None and stoplist != None and text != None and len(text) > 0:\n        # Preprocessing and cleansing\n        # Convert to lowercase, remove accents, punctuation and digits. Tokenize and remove stop-words.\n        textTokens = [word for word in utils.tokenize(text, lowercase=True, deacc=True, errors=\"ignore\")\n                            if word not in stoplist]\n\n        # The Bag-of-Words method takes the input text tokens (words) and returns a list of tuples\n        # containing the word's token-id (within the model dictionary (id2word)) and the word's frequency within the input text.\n        textBOW = model.id2word.doc2bow(textTokens)\n\n        # Given the textBOW, use the model to get the top topic\n        topTopicId = max( model[textBOW], key=lambda topic:topic[1])[0]\n        # Retrieve the topic terms (top 20 most probable words) from the model to include with the output returned\n        topTopicTerms = model.print_topic(topTopicId, topn=20)\n\n        topicTerms['topic'] = topTopicId\n        topicTerms['terms'] = topTopicTerms\n\n    return None if len(topicTerms) == 0 else topicTerms\n\ndef setStopWordList():\n\n    stoplist = {}\n    try:\n        import nltk\n        nltk.download(\"stopwords\")\n        stoplist = set(nltk.corpus.stopwords.words(\"english\"))\n    except:\n        stoplist = {}\n\n    if stoplist == {}: # Use a default, just in case\n        stoplist = {'because', 'during', 'was', 'itself', 'should', 'by', 'haven', 'yourself', 'been', 're', 'ain', 'hadn', 'had', 'again', 'what', 'they', 'themselves', 'whom', 'you', 'all', 'both', 'on', 'isn', 'his', 'ourselves', 'that', 't', 'm', 'is', 'this', 'how', 'when', 'will', 'against', 'her', 'with', 'couldn', 'being', 'hasn', 'be', 'it', 'but', 'no', 'than', 'don', 'most', 'now', 'while', 'doesn', 'our', 'from', 'are', 'he', 'so', 'shouldn', 've', 'y', 'as', 'we', 'll', 's', 'himself', 'my', 'about', 'more', 'where', 'down', 'there', 'just', 'nor', 'theirs', 'such', 'who', 'to', 'before', 'him', 'me', 'has', 'o', 'its', 'were', 'did', 'can', 'same', 'then', 'have', 'few', 'aren', 'd', 'other', 'further', 'and', 'off', 'these', 'an', 'wasn', 'hers', 'your', 'weren', 'until', 'only', 'does', 'shan', 'i', 'own', 'not', 'or', 'myself', 'through', 'some', 'didn', 'at', 'out', 'why', 'needn', 'doing', 'above', 'after', 'wouldn', 'yourselves', 'very', 'having', 'herself', 'a', 'the', 'am', 'if', 'into', 'once', 'won', 'too', 'up', 'ours', 'here', 'those', 'each', 'in', 'over', 'ma', 'them', 'under', 'for', 'mustn', 'yours', 'mightn', 'below', 'between', 'which', 'do', 'any', 'she', 'of', 'their'}\n\n    return stoplist\n","schema_mapping":[{"name":"model_id","type":"double","length":0,"source_elem_name":"","target_elem_name":""},{"name":"topic","type":"double","length":0,"source_elem_name":"","target_elem_name":""},{"name":"terms","type":"string","length":0,"source_elem_name":"","target_elem_name":""},{"name":"text","label":"counter (Number)","type":"string"}]},"app_data":{"ui_data":{"label":"Python Machine learning","x_pos":20,"y_pos":100}}},{"id":"objectstorage_v2_t5u28o9l8ur","type":"binding","op":"ibm.streams.targets.objectstorage_v2","parameters":{"format":"parquet","partition_value_attributes":["model_id"],"parquet_compression":"SNAPPY","write_policy":"numberOfEvents","rolling_number_of_events":"10000"},"connection":{"ref":"212176ed-cb0d-400e-a7d7-007e4fd8364a","project_ref":"50ac5cb5-7ca8-46c5-9429-4b348df1f962","properties":{"asset":{"id":"/pyml-output/pyML04-toptopics-%TIME.parq","name":"/pyml-output/pyML04-toptopics-%TIME.parq","path":"/pyml-output/pyML04-toptopics-%TIME.parq","type":"unknown"}}},"app_data":{"ui_data":{"label":"Cloud Object Storage","x_pos":270,"y_pos":150}}}]}],"schemas":[{"id":"schema0","fields":[{"name":"text","type":"string"},{"name":"stars","type":"double"}]},{"id":"schema1","fields":[{"name":"model_id","type":"double"},{"name":"topic","type":"double"},{"name":"terms","type":"string"},{"name":"text","type":"string"}]}]},"engines":{"streams":{"instance_id":"8f40c594-150e-4374-9ff4-71bd6d28f642"}}}}