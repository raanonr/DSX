{
    "metadata": {
        "kernelspec": {
            "language": "python", 
            "display_name": "Python 3.5 (Experimental) with Spark 2.1", 
            "name": "python3-spark21"
        }, 
        "language_info": {
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }, 
            "version": "3.5.2", 
            "name": "python", 
            "nbconvert_exporter": "python", 
            "mimetype": "text/x-python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py"
        }
    }, 
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 1, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "--2017-11-26 07:43:48--  https://raw.githubusercontent.com/Yura32000/practicals/master/watson_streaming_pipelines.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 8016 (7.8K) [text/plain]\nSaving to: \u2018watson_streaming_pipelines.py\u2019\n\n100%[======================================>] 8,016       --.-K/s   in 0s      \n\n2017-11-26 07:43:48 (23.8 MB/s) - \u2018watson_streaming_pipelines.py\u2019 saved [8016/8016]\n\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "source": "!rm -f watson_streaming_pipelines.py*\n!wget https://raw.githubusercontent.com/Yura32000/practicals/master/watson_streaming_pipelines.py", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "import watson_streaming_pipelines as wstp\n########################################################################################################################", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 3, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "# init() function will be called once on pipeline initialization\n# @state a Python dictionary object for keeping state. The state object is passed to the process function\ndef init(state):\n\n    cos_credentials = {\n        'iam_url':'https://iam.stage1.ng.bluemix.net/oidc/token',\n        'api_key':'xhjheSC7AhSLtvapSDnbyFn17uWUqW5ccAOuHhQxnnEY',\n        'resource_instance_id':'crn:v1:staging:public:cloud-object-storage:global:a/68a66698d275aeb48097f868957ab2ed:bbb5aa36-5525-4000-b129-bcb780195098::',\n        'url':'https://s3-api.us-geo.objectstorage.uat.service.networklayer.com',\n        'endpoint':'https://s3.us-west.objectstorage.uat.softlayer.net'\n    }\n\n    state['outmsg'], state['model'] = get_model( cos_credentials, 'pyml', 'LDA_test_1.model.pickle')\n    state['stoplist'] = setStopWordList()", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 30, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "def get_model( credentials, bucket_name, object_name):\n    \"\"\"\n    Load the model using the appropriate method (based on how it was saved).\n    In this example, the model was saved using 'pickle.dumps( self.model)'.\n    \"\"\"\n    import pickle\n    import gzip\n\n    model = None\n    outmsg = \"\"\n    \n    try:\n        pickledData = wstp.get_from_cloud_object_storage( \n            api_key = cos_credentials['api_key'],\n            full_object_path = bucket_name + '/' + object_name, \n            auth_endpoint = cos_credentials['iam_url'],\n            service_endpoint = cos_credentials['endpoint']\n        )\n        outmsg += \"len(pickledData) = \" + str(len(pickledData)) + \"; \"\n        print(len(pickledData))\n    except:\n        outmsg += \"Failed: get_from_cloud_object_storage(); \"       \n\n    if pickledData:\n        # model = wstp.deserializeObject( pickedData)\n        if pickledData.startswith(b\"\\x1f\\x8b\\x08\"): # Magic signature for gzip\n            model = pickle.loads( gzip.decompress( pickledData))\n        else:\n            model = pickle.loads( pickledData)\n\n        if model:\n            try:\n                outmsg += \"Read new model. Model topics = \" + str(model.num_topics) + \", Dictionary tokens = \" + str(len(model.id2word.keys()))                \n            except:\n                outmsg += \"Error reading model; \"\n\n    return outmsg, model", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 5, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "def setStopWordList():\n    import nltk\n\n    stoplist = {}\n\n    nltk.download(\"stopwords\")\n    stoplist = set(nltk.corpus.stopwords.words(\"english\"))\n\n    if len(stoplist) == 0: # Static, just in case\n        stoplist = {'because', 'during', 'was', 'itself'}\n        # stoplist = {'because', 'during', 'was', 'itself', 'should', 'by', 'haven', 'yourself', 'been', 're', 'ain', 'hadn', 'had', 'again', 'what', 'they', 'themselves', 'whom', 'you', 'all', 'both', 'on', 'isn', 'his', 'ourselves', 'that', 't', 'm', 'is', 'this', 'how', 'when', 'will', 'against', 'her', 'with', 'couldn', 'being', 'hasn', 'be', 'it', 'but', 'no', 'than', 'don', 'most', 'now', 'while', 'doesn', 'our', 'from', 'are', 'he', 'so', 'shouldn', 've', 'y', 'as', 'we', 'll', 's', 'himself', 'my', 'about', 'more', 'where', 'down', 'there', 'just', 'nor', 'theirs', 'such', 'who', 'to', 'before', 'him', 'me', 'has', 'o', 'its', 'were', 'did', 'can', 'same', 'then', 'have', 'few', 'aren', 'd', 'other', 'further', 'and', 'off', 'these', 'an', 'wasn', 'hers', 'your', 'weren', 'until', 'only', 'does', 'shan', 'i', 'own', 'not', 'or', 'myself', 'through', 'some', 'didn', 'at', 'out', 'why', 'needn', 'doing', 'above', 'after', 'wouldn', 'yourselves', 'very', 'having', 'herself', 'a', 'the', 'am', 'if', 'into', 'once', 'won', 'too', 'up', 'ours', 'here', 'those', 'each', 'in', 'over', 'ma', 'them', 'under', 'for', 'mustn', 'yours', 'mightn', 'below', 'between', 'which', 'do', 'any', 'she', 'of', 'their'}\n\n    return stoplist", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": 6, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "[nltk_data] Downloading package stopwords to /gpfs/fs01/user/sca9-7277\n[nltk_data]     eb31bca08b-bc196c953de3/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "source": "state = {}\ninit(state)", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "'Failed: get_from_cloud_object_storage(); '"
                    }, 
                    "execution_count": 7
                }
            ], 
            "cell_type": "code", 
            "source": "state['outmsg']", 
            "metadata": {}
        }, 
        {
            "execution_count": 10, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "3400501\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "source": "cos_credentials = {\n        'iam_url':'https://iam.stage1.ng.bluemix.net/oidc/token',\n        'api_key':'xhjheSC7AhSLtvapSDnbyFn17uWUqW5ccAOuHhQxnnEY',\n        'resource_instance_id':'crn:v1:staging:public:cloud-object-storage:global:a/68a66698d275aeb48097f868957ab2ed:bbb5aa36-5525-4000-b129-bcb780195098::',\n        'url':'https://s3-api.us-geo.objectstorage.uat.service.networklayer.com',\n        'endpoint':'https://s3.us-west.objectstorage.uat.softlayer.net'\n}\ndef get_model1( credentials, bucket_name, object_name):\n    \"\"\"\n    Load the model using the appropriate method (based on how it was saved).\n    In this example, the model was saved using 'pickle.dumps( self.model)'.\n    \"\"\"\n    import pickle\n    import gzip\n\n    model = None\n    outmsg = None\n    \n    pickledData = wstp.get_from_cloud_object_storage( \n            api_key = cos_credentials['api_key'],\n            full_object_path = bucket_name + '/' + object_name, \n            auth_endpoint = cos_credentials['iam_url'],\n            service_endpoint = cos_credentials['endpoint']\n    )\n    print(len(pickledData))\n    return pickledData\n\nstate['pickledData'] = get_model1( cos_credentials, 'pyml', 'LDA_test_1.model.pickle')", 
            "metadata": {}
        }, 
        {
            "execution_count": 14, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "Using TensorFlow backend.\n", 
                    "name": "stderr"
                }
            ], 
            "cell_type": "code", 
            "source": "import pickle\nimport gzip\n\n#print(state['pickledData'][0:30])\nmodel = pickle.loads( gzip.decompress( state['pickledData']))\n#model = pickle.loads( state['pickledData'])", 
            "metadata": {}
        }, 
        {
            "execution_count": 15, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "20"
                    }, 
                    "execution_count": 15
                }
            ], 
            "cell_type": "code", 
            "source": "model.num_topics", 
            "metadata": {}
        }, 
        {
            "execution_count": 16, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "32000"
                    }, 
                    "execution_count": 16
                }
            ], 
            "cell_type": "code", 
            "source": "len(model.id2word.keys())", 
            "metadata": {}
        }, 
        {
            "execution_count": 31, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "3400501\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "source": "outmsg, model = get_model( cos_credentials, 'pyml', 'LDA_test_1.model.pickle')", 
            "metadata": {}
        }, 
        {
            "execution_count": 32, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "len(pickledData) = 3400501; Read new model. Model topics = 20, Dictionary tokens = 32000\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "source": "print(outmsg)", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "outputs": [], 
            "cell_type": "code", 
            "source": "", 
            "metadata": {
                "collapsed": true
            }
        }
    ], 
    "nbformat": 4
}